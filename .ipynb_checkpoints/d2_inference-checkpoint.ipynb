{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting Detectron2 model on Sagemaker Inference endpoint\n",
    "\n",
    "Note that if you only wnat to deploy to a SageMaker Endpoint, you can skip the first few cells that require detectron2 to be built locally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the Test Set into D2 for metadata class info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data.catalog import MetadataCatalog, DatasetCatalog\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Use this if you have the dataset locally referencable \n",
    "# dataset_name = \"test\"\n",
    "# dataset_location = \"/data/\"\n",
    "# annotation_file = \"test.json\"\n",
    "# image_dir = \"test\"\n",
    "\n",
    "# Use this if you want to just create an empty dataset that has the classmap \n",
    "dataset_name = \"tmp\"\n",
    "dataset_location = \"\"\n",
    "annotation_file = \"\"\n",
    "image_dir = \"\"\n",
    "\n",
    "register_coco_instances(dataset_name, {}, os.path.join(dataset_location, annotation_file), \n",
    "                        os.path.join(dataset_location, image_dir))\n",
    "cb_meta = MetadataCatalog.get(dataset_name)\n",
    "\n",
    "# This section should be run just to be explicit to Detectron which classes are which! \n",
    "MetadataCatalog.get(val_dataset_name).thing_classes = ['OBJECT_1', 'OBJECT_2', 'OBJECT_3', 'OBJECT_4', 'OBJECT_5'] # put more here! \n",
    "MetadataCatalog.get(val_dataset_name).thing_dataset_id_to_contiguous_id={1: 0, 2: 1, 3: 2, 4: 3, 5: 4} # Update the mapping here as so too for class 0 to be background!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Model as SageMaker Endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "import sagemaker.session import Session\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# consts \n",
    "default_bucket = '<BUCKET-NAME>'\n",
    "sess = Session(default_bucket=default_bucket)\n",
    "role = '<SAGEMAKER-ROLE>' # An AWS IAM role (either name or full ARN).\n",
    "n = 'deploy'\n",
    "model_name = f\"d2-{n}\"\n",
    "endpoint_name = f\"d2-{n}\"\n",
    "\n",
    "# Update this with the model output location `model.tar.gz` file\n",
    "model_url = d2.latest_training_job.describe()['ModelArtifacts']['S3ModelArtifacts'] # Should look like s3://PATH_TO_OUTPUT/model.tar.gz\n",
    "\n",
    "'''source_dir is required for BYOM'''\n",
    "source_dir = '<S3-URI-OF-MODEL.TAR.GZ>'\n",
    "\n",
    "remote_model = PyTorchModel(\n",
    "                     # source_dir=source_dir\n",
    "                     name = model_name, \n",
    "                     model_data=model_url,\n",
    "                     role=role,\n",
    "                     sagemaker_session=sess,\n",
    "                     entry_point=\"inference.py\",\n",
    "                     # image=image, \n",
    "                     framework_version=\"1.6.0\",\n",
    "                     py_version='py3'\n",
    "                    )\n",
    "\n",
    "remote_predictor = remote_model.deploy(\n",
    "                         instance_type='ml.g4dn.xlarge', \n",
    "                         initial_instance_count=1,\n",
    "                         # define a unique endpoint name. if ommitedr, the name of the training job is used.\n",
    "                         endpoint_name=endpoint_name,  \n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call inference on some local test images! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from io import BytesIO\n",
    "from container_serving.d2_deserializer import json_to_d2\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import time \n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "accept_type = \"json\" \n",
    "content_type = 'image/jpeg'\n",
    "headers = {'content-type': content_type}\n",
    "device = \"cpu\" # cuda:0 for GPU, cpu for CPU\n",
    "test_pics_dir = '<PATH_TO_SOME_TEST_IMGS>'\n",
    "\n",
    "classID_name = {\n",
    "    0: 'OBJECT1',\n",
    "    1: 'OBJECT2',\n",
    "    2: 'OBJECT3',\n",
    "    3: 'OBJECT4',\n",
    "    4: 'OBJECT5',\n",
    "}\n",
    "\n",
    "for img_ in os.listdir(test_pics_dir): \n",
    "    \n",
    "    img_name = test_pics_dir + img_ \n",
    "    print(img_name) \n",
    "    \n",
    "    payload = open(img_name, 'rb')\n",
    "    device = \"cpu\"\n",
    "\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=payload,\n",
    "        ContentType=content_type,\n",
    "        Accept = accept_type\n",
    "    )\n",
    "    \n",
    "    if accept_type==\"json\":\n",
    "        predictions = json_to_d2(response['Body'].read(), device)\n",
    "    elif accept_type==\"detectron2\":\n",
    "        print(response['Body'].read())\n",
    "        stream = BytesIO(response['Body'].read())\n",
    "        predictions = pickle.loads(stream.read())\n",
    "        \n",
    "    # Extract preds: \n",
    "    preds = predictions[\"instances\"].to(\"cpu\")\n",
    "    boxes = preds.pred_boxes.tensor.numpy()\n",
    "    scores = preds.scores.tolist()\n",
    "    classes = preds.pred_classes.tolist()\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        left, top, right, bot = boxes[i] #x0, y0, x1, y1\n",
    "        print(f'DETECTED: {classID_name[classes[i]]}, confidence: {scores[i]}, box: {int(left)} {int(top)} {int(right)} {int(bot)}\\n') # left top right bot \n",
    "    \n",
    "    # visualize\n",
    "    im = cv2.imread(img_name)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=cb_meta, \n",
    "                   scale=0.8)\n",
    "    out = v.draw_instance_predictions(predictions[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoint for cost saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
